name: CD - Deploy to Dev & Staging

on:
   workflow_run:
    workflows: ["CI - Pull Request Checks"]
    types:
      - completed
  workflow_dispatch:  # Allow manual trigger
    inputs:
      skip_dev:
        description: 'Skip dev deployment'
        required: false
        default: false
        type: boolean
      skip_staging:
        description: 'Skip staging deployment'
        required: false
        default: false
        type: boolean

env:
  TERRAFORM_VERSION: '1.5.7'
  PYTHON_VERSION: '3.10'
  GCP_REGION: 'europe-west2'
  DEV_MODEL_BUCKET: 'manypets-ml-artifacts-dev'
  STAGING_MODEL_BUCKET: 'manypets-ml-artifacts-staging'

jobs:
  # Job 1: Build and Push Docker Images (No changes needed, kept for context)
  build-and-push:
    name: Build & Push Docker Images
    runs-on: ubuntu-latest
    
    permissions:
      contents: read
      id-token: write
    
    outputs:
      training_image_tag: ${{ steps.meta-training.outputs.tags }}
      api_image_tag: ${{ steps.prediction_service.outputs.tags }}
      image_version: ${{ steps.version.outputs.version }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Generate version tag
        id: version
        run: |
          VERSION=$(echo ${{ github.sha }} | cut -c1-7)
          echo "version=$VERSION" >> $GITHUB_OUTPUT
          echo "Generated version: $VERSION"
      
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}
      
      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
      
      - name: Configure Docker to use gcloud as credential helper
        run: gcloud auth configure-docker ${{ env.GCP_REGION }}-docker.pkg.dev
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      # Build Training Image
      - name: Docker metadata for training image
        id: meta-training
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-dev/training-images/claim-leakage-training
          tags: |
            type=sha,prefix=,format=short
            type=raw,value=latest
            type=raw,value=${{ steps.version.outputs.version }}
      
      - name: Build and push training image
        uses: docker/build-push-action@v5
        with:
          context: ml/training
          file: ml/training/Dockerfile
          push: true
          tags: ${{ steps.meta-training.outputs.tags }}
          labels: ${{ steps.meta-training.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            VERSION=${{ steps.version.outputs.version }}
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            GIT_COMMIT=${{ github.sha }}
      
      
      - name: Docker metadata for API image
        id: prediction_service
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-dev/serving-images/prediction-api
          tags: |
            type=sha,prefix=,format=short
            type=raw,value=latest
            type=raw,value=${{ steps.version.outputs.version }}
      
      - name: Build and push API image
        uses: docker/build-push-action@v5
        with:
          context: api
          file: api/Dockerfile
          push: true
          tags: ${{ steps.prediction_service.outputs.tags }}
          labels: ${{ steps.prediction_service.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            VERSION=${{ steps.version.outputs.version }}
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            GIT_COMMIT=${{ github.sha }}
      
      - name: Summary
        run: |
          echo "Docker Images Built Successfully" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Training Image:** \`${{ steps.meta-training.outputs.tags }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**API Image:** \`${{ steps.prediction_service.outputs.tags }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Version:** \`${{ steps.version.outputs.version }}\`" >> $GITHUB_STEP_SUMMARY

  # Job 2: Deploy to Dev (unchanged, kept for context)
  deploy-dev:
    name: Deploy to Dev
    runs-on: ubuntu-latest
    needs: build-and-push
    if: ${{ !inputs.skip_dev }}
    environment:
      name: dev
      url: https://claim-prediction-api-dev-xxxxx.run.app
    
    permissions:
      contents: read
      id-token: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Authenticate to Google Cloud (Dev)
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: cicd-pipeline-dev@manypets-ml-dev.iam.gserviceaccount.com
          project_id: manypets-ml-dev
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
      
      - name: Terraform Init
        run: terraform init
        working-directory: terraform/envs/dev
      
      - name: Terraform Apply
        run: |
          terraform apply -auto-approve \
            -var="api_container_image=${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-dev/serving-images/prediction-api:${{ needs.build-and-push.outputs.image_version }}" \
            -var="training_container_image=${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-dev/training-images/claim-leakage-training:${{ needs.build-and-push.outputs.image_version }}"
        working-directory: terraform/envs/dev
      
      - name: Get Cloud Run URL
        id: get-url
        run: |
          URL=$(gcloud run services describe claim-prediction-api-dev \
            --region=${{ env.GCP_REGION }} \
            --format='value(status.url)')
          echo "url=$URL" >> $GITHUB_OUTPUT
      
      - name: Wait for deployment to stabilize
        run: sleep 30
      
      - name: Run smoke tests
        run: |
          # Health check
          curl -f ${{ steps.get-url.outputs.url }}/healthz || exit 1
          
          # Test prediction endpoint (with dummy data)
          curl -X POST ${{ steps.get-url.outputs.url }}/predict \
            -H "Content-Type: application/json" \
            -d '{"claim_amount": 1000, "policy_age": 12}' \
            -f || exit 1
          
          echo " Smoke tests passed!"
      
      - name: Deployment summary
        run: |
          echo " Dev Deployment Successful" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** Dev" >> $GITHUB_STEP_SUMMARY
          echo "**Service URL:** ${{ steps.get-url.outputs.url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Image Version:** \`${{ needs.build-and-push.outputs.image_version }}\`" >> $GITHUB_STEP_SUMMARY

  # Job 3: Run Training Job in Dev
  train-model-dev:
    name: Train Model in Dev
    runs-on: ubuntu-latest
    needs: deploy-dev
    if: ${{ !inputs.skip_dev }}
    
    permissions:
      contents: read
      id-token: write
    
    steps:
      - name: Authenticate to Google Cloud (Dev)
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          # Use the Service Account with Vertex AI Training/Storage permissions
          service_account: cicd-pipeline-dev@manypets-ml-dev.iam.gserviceaccount.com
          project_id: manypets-ml-dev
      
      - name: Trigger Vertex AI Training Job (Custom Container)
        id: trigger-job
        run: |
          # 1. Define variables
          JOB_DISPLAY_NAME="leakage-train-dev-${{ needs.build-and-push.outputs.image_version }}"
          CONTAINER_IMAGE_URI="${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-dev/training-images/claim-leakage-training:${{ needs.build-and-push.outputs.image_version }}"
          
          # 2. Define the GCS output path dynamically
          # The path includes the version and timestamp for unique model artifacts
          GCS_MODEL_OUTPUT="gs://${{ env.DEV_MODEL_BUCKET }}/claim-outlier/models/${{ needs.build-and-push.outputs.image_version }}/model.pkl"
          
          echo "Training Image URI: $CONTAINER_IMAGE_URI"
          echo "GCS Model Output Path: $GCS_MODEL_OUTPUT"

          # 3. Trigger the job, passing the GCS path as an argument to your train.py script
          # The 'command' must match the ENTRYPOINT/CMD in the Dockerfile
          # The 'args' must match the argparse argument in your train.py script
          JOB_ID=$(gcloud ai custom-jobs create \
            --region=${{ env.GCP_REGION }} \
            --display-name="$JOB_DISPLAY_NAME" \
            --worker-pool-spec="machine-type=n1-standard-4,replica-count=1,container-image-uri=$CONTAINER_IMAGE_URI,command='python,train.py',args='--gcs-output-path,$GCS_MODEL_OUTPUT'" \
            --service-account=vertex-ai-training-dev@manypets-ml-dev.iam.gserviceaccount.com \
            --format='value(name)')
            
          # Output the job name for the summary
          echo "job_name=$JOB_DISPLAY_NAME" >> $GITHUB_OUTPUT
          echo "gcs_path=$GCS_MODEL_OUTPUT" >> $GITHUB_OUTPUT

      - name: Training job summary
        run: |
          echo "### ðŸŽ¯ Training Job Triggered (Dev)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** Dev" >> $GITHUB_STEP_SUMMARY
          echo "**Job Name:** \`${{ steps.trigger-job.outputs.job_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Model Output:** \`${{ steps.trigger-job.outputs.gcs_path }}\`" >> $GITHUB_STEP_SUMMARY
          echo "Check Vertex AI Jobs Console for progress."

  # Job 4: Copy images to staging registry (unchanged)
  promote-images-to-staging:
    name: Promote Images to Staging
    runs-on: ubuntu-latest
    needs: [build-and-push, train-model-dev] # Depend on training job completion for dev environment
    if: ${{ !inputs.skip_staging }}
    
    permissions:
      contents: read
      id-token: write
    
    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: ${{ secrets.WIF_SERVICE_ACCOUNT }}
      
      - name: Copy training image to staging
        run: |
          gcloud container images add-tag \
            ${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-dev/training-images/claim-outlier-training:${{ needs.build-and-push.outputs.image_version }} \
            ${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-staging/training-images/claim-outlier-training:${{ needs.build-and-push.outputs.image_version }} \
            --quiet
      
      - name: Copy API image to staging
        run: |
          gcloud container images add-tag \
            ${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-dev/serving-images/prediction-api:${{ needs.build-and-push.outputs.image_version }} \
            ${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-staging/serving-images/prediction-api:${{ needs.build-and-push.outputs.image_version }} \
            --quiet

  
  deploy-staging:
    name: Deploy to Staging
    runs-on: ubuntu-latest
    needs: [build-and-push, promote-images-to-staging]
    if: ${{ !inputs.skip_staging }}
    environment:
      name: staging
      url: https://claim-prediction-api-staging-xxxxx.run.app
    
    permissions:
      contents: read
      id-token: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Authenticate to Google Cloud (Staging)
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          service_account: cicd-pipeline-staging@manypets-ml-staging.iam.gserviceaccount.com
          project_id: manypets-ml-staging
      
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TERRAFORM_VERSION }}
      
      - name: Terraform Init
        run: terraform init
        working-directory: terraform/envs/staging
      
      - name: Terraform Apply
        run: |
          terraform apply -auto-approve \
            -var="api_container_image=${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-staging/serving-images/prediction-api:${{ needs.build-and-push.outputs.image_version }}" \
            -var="training_container_image=${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-staging/training-images/claim-leakage-training:${{ needs.build-and-push.outputs.image_version }}"
        working-directory: terraform/envs/staging
      
      - name: Get Cloud Run URL
        id: get-url
        run: |
          URL=$(gcloud run services describe claim-prediction-api-staging \
            --region=${{ env.GCP_REGION }} \
            --format='value(status.url)')
          echo "url=$URL" >> $GITHUB_OUTPUT
      
      - name: Wait for deployment to stabilize
        run: sleep 30
      
      - name: Run integration tests
        run: |
          # Health check
          curl -f ${{ steps.get-url.outputs.url }}/health || exit 1
          
          # Load test with Apache Bench
          ab -n 100 -c 10 ${{ steps.get-url.outputs.url }}/health
          
          # Test prediction endpoint
          curl -X POST ${{ steps.get-url.outputs.url }}/predict/claim-leakage \
            -H "Content-Type: application/json" \
            -d '{"claim_amount": 1000, "policy_age": 12}' \
            -f || exit 1
          
          echo " Integration tests passed!"
      
      - name: Deployment summary
        run: |
          echo " Staging Deployment Successful" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** Staging" >> $GITHUB_STEP_SUMMARY
          echo "**Service URL:** ${{ steps.get-url.outputs.url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Image Version:** \`${{ needs.build-and-push.outputs.image_version }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Ready for production deployment!" >> $GITHUB_STEP_SUMMARY
      
      - name: Notify team (Slack)
        if: always()
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          curl -X POST $SLACK_WEBHOOK \
            -H 'Content-Type: application/json' \
            -d "{\"text\":\"Staging deployment successful! Version: \`${{ needs.build-and-push.outputs.image_version }}\` is ready for production approval.\"}"

  # Job 6: Create GitHub Release (unchanged, kept for context)
  create-release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    needs: [build-and-push, deploy-staging]
    if: ${{ !inputs.skip_staging }}
    
    permissions:
      contents: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Generate changelog
        id: changelog
        run: |
          PREVIOUS_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "")
          if [ -z "$PREVIOUS_TAG" ]; then
            CHANGELOG=$(git log --oneline --pretty=format:"- %s" HEAD~10..HEAD)
          else
            CHANGELOG=$(git log --oneline --pretty=format:"- %s" $PREVIOUS_TAG..HEAD)
          fi
          echo "changelog<<EOF" >> $GITHUB_OUTPUT
          echo "$CHANGELOG" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
      
      - name: Create Release
        uses: actions/create-release@v1
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: v${{ needs.build-and-push.outputs.image_version }}
          release_name: Release v${{ needs.build-and-push.outputs.image_version }}
          body: |
            ## Release v${{ needs.build-and-push.outputs.image_version }}
            
            ### Changes
            ${{ steps.changelog.outputs.changelog }}
            
            ### Docker Images
            - **Training Image:** `${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-staging/training-images/claim-leakage-training:${{ needs.build-and-push.outputs.image_version }}`
            - **API Image:** `${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-staging/serving-images/prediction-api:${{ needs.build-and-push.outputs.image_version }}`
            
            ### Deployments
            - âœ… Dev: Deployed and tested
            - âœ… Staging: Deployed and tested
            - â³ Prod: Awaiting manual approval
            
            To deploy to production, run the "Deploy to Production" workflow manually.
          draft: false
          prerelease: false

  # Job 7: Run Training Job in Staging (NEW)
  train-model-staging:
    name: Train Model in Staging
    runs-on: ubuntu-latest
    needs: deploy-staging # Depends on successful deployment to Staging
    if: ${{ !inputs.skip_staging }}
    
    permissions:
      contents: read
      id-token: write
    
    steps:
      - name: Authenticate to Google Cloud (Staging)
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}
          # Use the Staging Service Account with Vertex AI Training/Storage permissions
          service_account: cicd-pipeline-staging@manypets-ml-staging.iam.gserviceaccount.com
          project_id: manypets-ml-staging # Assumes project ID is part of the SA email
      
      - name: Trigger Vertex AI Training Job (Custom Container)
        id: trigger-job
        run: |
          # 1. Define variables
          JOB_DISPLAY_NAME="leakage-train-staging-${{ needs.build-and-push.outputs.image_version }}"
          CONTAINER_IMAGE_URI="${{ env.GCP_REGION }}-docker.pkg.dev/manypets-ml-staging/training-images/claim-leakage-training:${{ needs.build-and-push.outputs.image_version }}"
          
          # 2. Define the GCS output path dynamically
          # This model is the one that will ultimately be registered for Production
          GCS_MODEL_OUTPUT="gs://${{ env.STAGING_MODEL_BUCKET }}/claim-leakage/models/${{ needs.build-and-push.outputs.image_version }}/model.pkl"
          
          echo "Training Image URI: $CONTAINER_IMAGE_URI"
          echo "GCS Model Output Path: $GCS_MODEL_OUTPUT"

          # 3. Trigger the job, passing the GCS path as an argument
          JOB_ID=$(gcloud ai custom-jobs create \
            --region=${{ env.GCP_REGION }} \
            --display-name="$JOB_DISPLAY_NAME" \
            --worker-pool-spec="machine-type=n1-standard-4,replica-count=1,container-image-uri=$CONTAINER_IMAGE_URI,command='python,train.py',args='--gcs-output-path,$GCS_MODEL_OUTPUT'" \
            --service-account=vertex-ai-training-staging@manypets-ml-staging.iam.gserviceaccount.com \
            --format='value(name)')
            
          # Output the job name for the summary
          echo "job_name=$JOB_DISPLAY_NAME" >> $GITHUB_OUTPUT
          echo "gcs_path=$GCS_MODEL_OUTPUT" >> $GITHUB_OUTPUT

      - name: Training job summary
        run: |
          echo " Training Job Triggered (Staging)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Environment:** Staging" >> $GITHUB_STEP_SUMMARY
          echo "**Job Name:** \`${{ steps.trigger-job.outputs.job_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Model Output:** \`${{ steps.trigger-job.outputs.gcs_path }}\`" >> $GITHUB_STEP_SUMMARY
          echo "Check Vertex AI Jobs Console for progress."